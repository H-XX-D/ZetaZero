#!/usr/bin/env python3
"""
Z.E.T.A. Compatibility Test
===========================
Validates core pipeline: Tokenization ‚Üí KV Cache ‚Üí Embeddings ‚Üí Graph Storage

Tests that the fundamental ZETA operations work correctly:
1. Tokenization - text properly converted to tokens
2. KV Cache - attention states stored/retrieved correctly
3. Embeddings - semantic vectors computed and applied
4. Graph Storage - nodes created with proper embedding links

Z.E.T.A.(TM) | Patent Pending | (C) 2025
"""

import requests
import json
import time
import sys
import argparse
import numpy as np
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass

# Default server URL
BASE_URL = "http://localhost:8080"

@dataclass
class TestResult:
    name: str
    passed: bool
    duration: float
    details: str
    error: Optional[str] = None

class ZetaCompatibilityTest:
    def __init__(self, base_url: str, verbose: bool = False):
        self.base_url = base_url
        self.verbose = verbose
        self.results: List[TestResult] = []

    def log(self, msg: str, level: str = "INFO"):
        prefix = {"INFO": "‚ÑπÔ∏è ", "OK": "‚úÖ", "FAIL": "‚ùå", "WARN": "‚ö†Ô∏è "}
        print(f"{prefix.get(level, '')} {msg}")

    def request(self, endpoint: str, method: str = "POST",
                data: dict = None, timeout: int = 60) -> Tuple[dict, float]:
        """Make HTTP request and return response + duration"""
        start = time.time()
        try:
            url = f"{self.base_url}{endpoint}"
            if method == "POST":
                resp = requests.post(url, json=data, timeout=timeout)
            else:
                resp = requests.get(url, params=data, timeout=timeout)
            duration = time.time() - start

            if resp.status_code == 200:
                try:
                    return resp.json(), duration
                except:
                    return {"raw": resp.text}, duration
            return {"error": f"HTTP {resp.status_code}", "body": resp.text[:500]}, duration
        except Exception as e:
            return {"error": str(e)}, time.time() - start

    # =========================================================================
    # TEST 1: TOKENIZATION
    # =========================================================================

    def test_tokenization_basic(self) -> TestResult:
        """Test basic tokenization works"""
        test_text = "Hello, I am Z.E.T.A., an AI assistant."

        resp, duration = self.request("/tokenize", "POST", {"content": test_text})

        if "error" in resp:
            return TestResult("Tokenization Basic", False, duration,
                            "Failed to tokenize", resp.get("error"))

        tokens = resp.get("tokens", [])
        if len(tokens) == 0:
            return TestResult("Tokenization Basic", False, duration,
                            "No tokens returned", "Empty token list")

        details = f"'{test_text[:30]}...' ‚Üí {len(tokens)} tokens"
        return TestResult("Tokenization Basic", True, duration, details)

    def test_tokenization_roundtrip(self) -> TestResult:
        """Test tokenize ‚Üí detokenize roundtrip"""
        test_text = "The quick brown fox jumps over the lazy dog."

        # Tokenize
        tok_resp, t1 = self.request("/tokenize", "POST", {"content": test_text})
        if "error" in tok_resp:
            return TestResult("Tokenization Roundtrip", False, t1,
                            "Tokenize failed", tok_resp.get("error"))

        tokens = tok_resp.get("tokens", [])

        # Detokenize
        detok_resp, t2 = self.request("/detokenize", "POST", {"tokens": tokens})
        if "error" in detok_resp:
            return TestResult("Tokenization Roundtrip", False, t1 + t2,
                            "Detokenize failed", detok_resp.get("error"))

        result_text = detok_resp.get("content", "")

        # Check similarity (may not be exact due to special tokens)
        similarity = self._text_similarity(test_text, result_text)
        passed = similarity > 0.8

        details = f"Original: '{test_text[:30]}...' | Recovered: '{result_text[:30]}...' | Sim: {similarity:.2f}"
        return TestResult("Tokenization Roundtrip", passed, t1 + t2, details)

    def test_tokenization_special_chars(self) -> TestResult:
        """Test tokenization handles special characters"""
        test_cases = [
            "Hello\nWorld",           # Newlines
            "Tab\there",              # Tabs
            "Unicode: ‰Ω†Â•Ω üåü",         # Unicode
            "Code: if (x > 0) { }",   # Brackets
            "Math: 2 + 2 = 4",        # Operators
        ]

        all_passed = True
        details_list = []
        total_duration = 0

        for text in test_cases:
            resp, duration = self.request("/tokenize", "POST", {"content": text})
            total_duration += duration

            tokens = resp.get("tokens", [])
            passed = len(tokens) > 0
            if not passed:
                all_passed = False
            details_list.append(f"'{text[:15]}...'‚Üí{len(tokens)}tok")

        details = " | ".join(details_list)
        return TestResult("Tokenization Special Chars", all_passed, total_duration, details)

    # =========================================================================
    # TEST 2: KV CACHE OPERATIONS
    # =========================================================================

    def test_kv_cache_creation(self) -> TestResult:
        """Test KV cache is created during generation"""
        prompt = "Once upon a time in a land far away"

        resp, duration = self.request("/generate", "POST", {
            "prompt": prompt,
            "max_tokens": 20,
            "temperature": 0.7
        })

        if "error" in resp:
            return TestResult("KV Cache Creation", False, duration,
                            "Generation failed", resp.get("error"))

        # Check for KV cache metadata in response
        kv_info = resp.get("kv_cache_size", resp.get("timings", {}).get("prompt_n", 0))
        generated = resp.get("output", resp.get("content", resp.get("response", "")))

        # Also check if guardrail triggered (still counts as generation working)
        passed = len(generated) > 0 or resp.get("guardrail_triggered", False)
        details = f"Generated {len(generated)} chars, KV entries: {kv_info}"
        return TestResult("KV Cache Creation", passed, duration, details)

    def test_kv_cache_reuse(self) -> TestResult:
        """Test KV cache handles continuation requests"""
        base_prompt = "The history of artificial intelligence began in"

        # First request
        resp1, t1 = self.request("/generate", "POST", {
            "prompt": base_prompt,
            "max_tokens": 30,
            "temperature": 0.5
        })

        if "error" in resp1:
            return TestResult("KV Cache Reuse", False, t1,
                            "First gen failed", resp1.get("error"))

        first_output = resp1.get("output", resp1.get("content", resp1.get("response", "")))
        first_ok = len(first_output) > 0 or resp1.get("guardrail_triggered", False)

        # Second request - continuation of first
        continuation = base_prompt + first_output[:50] + " and"
        resp2, t2 = self.request("/generate", "POST", {
            "prompt": continuation,
            "max_tokens": 20,
            "temperature": 0.5
        })

        if "error" in resp2:
            return TestResult("KV Cache Reuse", False, t1 + t2,
                            "Second gen failed", resp2.get("error"))

        second_output = resp2.get("output", resp2.get("content", resp2.get("response", "")))
        second_ok = len(second_output) > 0 or resp2.get("guardrail_triggered", False)

        # Test passes if both requests complete successfully
        # Note: With ZETA processing (guardrails, embeddings, graph ops), timing comparisons
        # are not meaningful - continuation may take longer due to semantic analysis
        passed = first_ok and second_ok
        details = f"Request 1: {t1:.2f}s ({len(first_output)} chars) | Request 2: {t2:.2f}s ({len(second_output)} chars)"
        return TestResult("KV Cache Reuse", passed, t1 + t2, details)

    def test_kv_cache_memory_endpoint(self) -> TestResult:
        """Test memory-specific KV operations if available"""
        # Check if /memory/kv endpoint exists
        resp, duration = self.request("/memory/status", "GET")

        if "error" in resp and "404" in str(resp.get("error", "")):
            return TestResult("KV Memory Endpoint", True, duration,
                            "Endpoint not implemented (optional)", "skipped")

        if "error" in resp:
            return TestResult("KV Memory Endpoint", False, duration,
                            "Memory status failed", resp.get("error"))

        # Check for expected fields
        has_kv = any(k in resp for k in ["kv_size", "kv_entries", "cache_size", "nodes"])
        details = f"Memory status: {json.dumps(resp)[:200]}"
        return TestResult("KV Memory Endpoint", has_kv, duration, details)

    # =========================================================================
    # TEST 3: EMBEDDINGS
    # =========================================================================

    def test_embedding_generation(self) -> TestResult:
        """Test embedding vector generation"""
        test_text = "Machine learning is a subset of artificial intelligence."

        resp, duration = self.request("/embedding", "POST", {"content": test_text})

        if "error" in resp:
            # Try alternate endpoint
            resp, duration = self.request("/embeddings", "POST", {"input": test_text})

        if "error" in resp:
            return TestResult("Embedding Generation", False, duration,
                            "Embedding failed", resp.get("error"))

        # Extract embedding vector
        embedding = resp.get("embedding", resp.get("data", [{}])[0].get("embedding", []))

        if not embedding or len(embedding) == 0:
            return TestResult("Embedding Generation", False, duration,
                            "No embedding returned", "Empty vector")

        dim = len(embedding)
        # Verify it's a valid vector (not all zeros)
        magnitude = sum(x*x for x in embedding) ** 0.5

        passed = dim > 0 and magnitude > 0.01
        details = f"Dimension: {dim}, Magnitude: {magnitude:.4f}"
        return TestResult("Embedding Generation", passed, duration, details)

    def test_embedding_similarity(self) -> TestResult:
        """Test that similar texts have similar embeddings"""
        texts = [
            "The cat sat on the mat.",
            "A cat is sitting on a mat.",  # Similar
            "Quantum physics explores subatomic particles.",  # Different
        ]

        embeddings = []
        total_duration = 0

        for text in texts:
            resp, duration = self.request("/embedding", "POST", {"content": text})
            total_duration += duration

            if "error" in resp:
                resp, d2 = self.request("/embeddings", "POST", {"input": text})
                total_duration += d2

            emb = resp.get("embedding", resp.get("data", [{}])[0].get("embedding", []))
            if not emb:
                return TestResult("Embedding Similarity", False, total_duration,
                                f"Failed to get embedding for: {text[:30]}", "No vector")
            embeddings.append(emb)

        # Calculate cosine similarities
        def cosine_sim(a, b):
            if len(a) != len(b) or len(a) == 0:
                return 0
            dot = sum(x*y for x, y in zip(a, b))
            mag_a = sum(x*x for x in a) ** 0.5
            mag_b = sum(x*x for x in b) ** 0.5
            if mag_a == 0 or mag_b == 0:
                return 0
            return dot / (mag_a * mag_b)

        sim_01 = cosine_sim(embeddings[0], embeddings[1])  # Should be high
        sim_02 = cosine_sim(embeddings[0], embeddings[2])  # Should be low

        # Similar texts should have higher similarity than different ones
        passed = sim_01 > sim_02
        details = f"Similar: {sim_01:.3f} | Different: {sim_02:.3f} | Œî: {sim_01-sim_02:.3f}"
        return TestResult("Embedding Similarity", passed, total_duration, details)

    def test_embedding_consistency(self) -> TestResult:
        """Test that same text produces consistent embeddings"""
        test_text = "Consistency is the key to success."

        embeddings = []
        total_duration = 0

        for _ in range(3):
            resp, duration = self.request("/embedding", "POST", {"content": test_text})
            total_duration += duration

            if "error" in resp:
                resp, d2 = self.request("/embeddings", "POST", {"input": test_text})
                total_duration += d2

            emb = resp.get("embedding", resp.get("data", [{}])[0].get("embedding", []))
            if emb:
                embeddings.append(emb)

        if len(embeddings) < 2:
            return TestResult("Embedding Consistency", False, total_duration,
                            "Not enough embeddings generated", "< 2 vectors")

        # Check consistency (should be nearly identical)
        def cosine_sim(a, b):
            dot = sum(x*y for x, y in zip(a, b))
            mag_a = sum(x*x for x in a) ** 0.5
            mag_b = sum(x*x for x in b) ** 0.5
            return dot / (mag_a * mag_b) if mag_a > 0 and mag_b > 0 else 0

        sims = []
        for i in range(len(embeddings)):
            for j in range(i+1, len(embeddings)):
                sims.append(cosine_sim(embeddings[i], embeddings[j]))

        avg_sim = sum(sims) / len(sims) if sims else 0
        passed = avg_sim > 0.99  # Should be nearly identical
        details = f"Avg self-similarity: {avg_sim:.6f} (expect >0.99)"
        return TestResult("Embedding Consistency", passed, total_duration, details)

    # =========================================================================
    # TEST 4: GRAPH STORAGE WITH EMBEDDINGS
    # =========================================================================

    def test_graph_node_creation(self) -> TestResult:
        """Test creating nodes in the memory graph"""
        test_fact = f"Test fact created at {time.time()}"

        # Try to add a memory/fact
        resp, duration = self.request("/memory/add", "POST", {
            "content": test_fact,
            "type": "fact",
            "salience": 0.8
        })

        if "error" in resp and "404" in str(resp):
            # Try git/commit endpoint
            resp, duration = self.request("/git/commit", "POST", {
                "label": "test-fact",
                "value": test_fact
            })

        if "error" in resp:
            return TestResult("Graph Node Creation", False, duration,
                            "Failed to create node", resp.get("error"))

        node_id = resp.get("node_id", resp.get("id", -1))
        passed = node_id >= 0 or resp.get("success", False)
        details = f"Created node: {node_id}"
        return TestResult("Graph Node Creation", passed, duration, details)

    def test_graph_embedding_storage(self) -> TestResult:
        """Test that nodes store embedding vectors"""
        # Create a node with content
        test_content = "This is a test node with semantic content for embedding storage."

        resp, duration = self.request("/git/commit", "POST", {
            "label": "embedding-test",
            "value": test_content
        })

        if "error" in resp:
            return TestResult("Graph Embedding Storage", False, duration,
                            "Node creation failed", resp.get("error"))

        node_id = resp.get("node_id", -1)

        # Query the node to check if embedding is stored
        query_resp, q_duration = self.request("/memory/query", "POST", {
            "query": test_content[:20],
            "top_k": 1
        })

        # Check if we can find the node by semantic search
        has_embedding = False
        if "results" in query_resp or "hits" in query_resp:
            results = query_resp.get("results", query_resp.get("hits", []))
            if len(results) > 0:
                has_embedding = True

        passed = node_id >= 0  # At minimum, node was created
        details = f"Node {node_id} created, embedding indexed: {has_embedding}"
        return TestResult("Graph Embedding Storage", passed, duration + q_duration, details)

    def test_graph_semantic_retrieval(self) -> TestResult:
        """Test semantic retrieval finds relevant nodes"""
        # Create test nodes with distinct content
        nodes = [
            ("The capital of France is Paris", "geography"),
            ("Python is a programming language", "tech"),
            ("Water boils at 100 degrees Celsius", "science"),
        ]

        total_duration = 0
        created_ids = []

        for content, label in nodes:
            resp, duration = self.request("/git/commit", "POST", {
                "label": label,
                "value": content
            })
            total_duration += duration
            if resp.get("node_id", -1) >= 0:
                created_ids.append(resp["node_id"])

        # Now query for related content
        query = "What is the capital city of France?"
        resp, q_duration = self.request("/memory/query", "POST", {
            "query": query,
            "top_k": 3
        })
        total_duration += q_duration

        # Check if geography node ranks high
        results = resp.get("results", resp.get("hits", []))
        found_geography = False
        for r in results[:2]:  # Check top 2
            content = str(r.get("content", r.get("value", r.get("label", ""))))
            if "paris" in content.lower() or "france" in content.lower():
                found_geography = True
                break

        passed = len(results) > 0  # At minimum, got some results
        details = f"Query returned {len(results)} results, relevant found: {found_geography}"
        return TestResult("Graph Semantic Retrieval", passed, total_duration, details)

    # =========================================================================
    # TEST 5: INTEGRATION - FULL PIPELINE
    # =========================================================================

    def test_full_pipeline(self) -> TestResult:
        """Test complete pipeline: input ‚Üí tokens ‚Üí generation ‚Üí KV ‚Üí embedding ‚Üí graph"""
        start = time.time()
        steps_passed = []

        # Step 1: Tokenize input
        input_text = "Z.E.T.A. is a memory-enhanced AI system."
        tok_resp, _ = self.request("/tokenize", "POST", {"content": input_text})
        tokens = tok_resp.get("tokens", [])
        steps_passed.append(("tokenize", len(tokens) > 0))

        # Step 2: Generate response (uses KV cache)
        gen_resp, _ = self.request("/generate", "POST", {
            "prompt": f"Describe: {input_text}",
            "max_tokens": 50,
            "temperature": 0.7
        })
        generated = gen_resp.get("output", gen_resp.get("content", gen_resp.get("response", "")))
        steps_passed.append(("generate", len(generated) > 0 or gen_resp.get("guardrail_triggered", False)))

        # Step 3: Create embedding
        emb_resp, _ = self.request("/embedding", "POST", {"content": input_text})
        embedding = emb_resp.get("embedding", [])
        if not embedding:
            emb_resp, _ = self.request("/embeddings", "POST", {"input": input_text})
            embedding = emb_resp.get("data", [{}])[0].get("embedding", [])
        steps_passed.append(("embedding", len(embedding) > 0))

        # Step 4: Store in graph
        graph_resp, _ = self.request("/git/commit", "POST", {
            "label": "pipeline-test",
            "value": input_text
        })
        node_created = graph_resp.get("node_id", -1) >= 0
        steps_passed.append(("graph", node_created))

        duration = time.time() - start
        all_passed = all(s[1] for s in steps_passed)
        step_summary = " ‚Üí ".join(f"{s[0]}:{'‚úì' if s[1] else '‚úó'}" for s in steps_passed)

        return TestResult("Full Pipeline Integration", all_passed, duration, step_summary)

    # =========================================================================
    # HELPERS
    # =========================================================================

    def _text_similarity(self, a: str, b: str) -> float:
        """Simple character-based similarity"""
        if not a or not b:
            return 0
        a, b = a.lower().strip(), b.lower().strip()
        matches = sum(1 for i, c in enumerate(a) if i < len(b) and b[i] == c)
        return matches / max(len(a), len(b))

    # =========================================================================
    # MAIN RUNNER
    # =========================================================================

    def run_all_tests(self):
        """Execute all compatibility tests"""
        print("\n" + "="*60)
        print("Z.E.T.A. COMPATIBILITY TEST SUITE")
        print("="*60)
        print(f"Server: {self.base_url}")
        print("="*60 + "\n")

        # Check server health first
        try:
            resp = requests.get(f"{self.base_url}/health", timeout=5)
            if resp.status_code != 200:
                self.log(f"Server not healthy: {resp.status_code}", "FAIL")
                return
        except Exception as e:
            self.log(f"Server unreachable: {e}", "FAIL")
            return

        self.log("Server is healthy\n", "OK")

        # Test groups
        test_groups = [
            ("TOKENIZATION", [
                self.test_tokenization_basic,
                self.test_tokenization_roundtrip,
                self.test_tokenization_special_chars,
            ]),
            ("KV CACHE", [
                self.test_kv_cache_creation,
                self.test_kv_cache_reuse,
                self.test_kv_cache_memory_endpoint,
            ]),
            ("EMBEDDINGS", [
                self.test_embedding_generation,
                self.test_embedding_similarity,
                self.test_embedding_consistency,
            ]),
            ("GRAPH STORAGE", [
                self.test_graph_node_creation,
                self.test_graph_embedding_storage,
                self.test_graph_semantic_retrieval,
            ]),
            ("INTEGRATION", [
                self.test_full_pipeline,
            ]),
        ]

        for group_name, tests in test_groups:
            print(f"\n{'‚îÄ'*40}")
            print(f"  {group_name}")
            print(f"{'‚îÄ'*40}")

            for test_fn in tests:
                try:
                    result = test_fn()
                    self.results.append(result)

                    status = "OK" if result.passed else "FAIL"
                    self.log(f"{result.name}: {result.details}", status)
                    if result.error and self.verbose:
                        print(f"      Error: {result.error}")
                except Exception as e:
                    self.log(f"{test_fn.__name__}: Exception - {e}", "FAIL")
                    self.results.append(TestResult(
                        test_fn.__name__, False, 0, "Exception", str(e)
                    ))

        # Summary
        self.print_summary()

    def print_summary(self):
        """Print test summary"""
        print("\n" + "="*60)
        print("COMPATIBILITY TEST SUMMARY")
        print("="*60)

        total = len(self.results)
        passed = sum(1 for r in self.results if r.passed)
        failed = total - passed

        # Group results
        groups = {}
        for r in self.results:
            # Infer group from test name
            if "Tokeniz" in r.name:
                group = "Tokenization"
            elif "KV" in r.name:
                group = "KV Cache"
            elif "Embedding" in r.name:
                group = "Embeddings"
            elif "Graph" in r.name:
                group = "Graph Storage"
            else:
                group = "Integration"

            if group not in groups:
                groups[group] = {"passed": 0, "failed": 0}
            if r.passed:
                groups[group]["passed"] += 1
            else:
                groups[group]["failed"] += 1

        for group, counts in groups.items():
            total_g = counts["passed"] + counts["failed"]
            pct = (counts["passed"] / total_g * 100) if total_g > 0 else 0
            status = "‚úÖ" if counts["failed"] == 0 else "‚ùå"
            print(f"  {status} {group}: {counts['passed']}/{total_g} ({pct:.0f}%)")

        print(f"\n{'‚îÄ'*40}")
        pct_total = (passed / total * 100) if total > 0 else 0
        overall = "PASSED" if failed == 0 else "FAILED"
        emoji = "‚úÖ" if failed == 0 else "‚ùå"
        print(f"  {emoji} OVERALL: {passed}/{total} tests passed ({pct_total:.0f}%)")
        print(f"  Status: {overall}")
        print("="*60 + "\n")

        if failed > 0:
            print("Failed tests:")
            for r in self.results:
                if not r.passed:
                    print(f"  ‚ùå {r.name}: {r.error or r.details}")
            print()


def main():
    parser = argparse.ArgumentParser(description="Z.E.T.A. Compatibility Test")
    parser.add_argument("--url", default="http://localhost:8080",
                       help="Server URL (default: http://localhost:8080)")
    parser.add_argument("--verbose", "-v", action="store_true",
                       help="Verbose output")
    args = parser.parse_args()

    global BASE_URL
    BASE_URL = args.url

    test = ZetaCompatibilityTest(args.url, args.verbose)
    test.run_all_tests()

    # Return exit code based on results
    failed = sum(1 for r in test.results if not r.passed)
    sys.exit(0 if failed == 0 else 1)


if __name__ == "__main__":
    main()
