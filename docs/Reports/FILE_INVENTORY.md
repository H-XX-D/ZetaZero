# ZetaLm: Comprehensive File Inventory

**Last Updated:** December 9, 2025  
**Total Files:** 50+ source files + configs + models  
**Architecture:** Metal-first Swift inference engine with quantum-inspired optimizations

---

## ğŸ“‹ Directory Structure & File Purposes

### ğŸ“¦ **Root Level Configuration**

| File | Purpose | Status |
|------|---------|--------|
| `Package.swift` | Swift Package Manager manifest with dependencies | âœ… Active |
| `README.md` | Primary project documentation | âœ… Active |
| `.gitignore` | Git ignore rules | âœ… Active |
| `LICENSE` | Apache License 2.0 | âœ… Active |
| `CODE_OF_CONDUCT.md` | Community guidelines | âœ… Reference |
| `CONTRIBUTING.md` | Contribution guidelines | âœ… Reference |
| `SECURITY.md` | Security policy | âœ… Reference |
| `CHANGELOG.md` | Version history and changes | âœ… Reference |

---

## ğŸ”§ Core Engine Files (Root)

### Primary Inference Engines

| File | Lines | Purpose | Key Features |
|------|-------|---------|--------------|
| `ZetaGGUFEngine.swift` | 600+ | **Main inference orchestrator** | â€¢ Variational gating<br>â€¢ Quantum superposition sampling<br>â€¢ Pre-allocated buffer management<br>â€¢ Multi-mode generation (optimistic, variational, ultimate)<br>â€¢ Entropy-based sparse/dense switching |
| `ZetaMPSEngine.swift` | 533 | Metal Performance Shaders hybrid engine | â€¢ MPSMatrixMultiplication<br>â€¢ MPSMatrixSoftMax<br>â€¢ Fallback lightweight kernels<br>â€¢ Experimental alternative to core engine |
| `UniversalInferenceEngine.swift` | ? | Format-agnostic inference wrapper | (see Engines/) |

### Supporting Core Files

| File | Lines | Purpose | Key Features |
|------|-------|---------|--------------|
| `ZetaModel.swift` | 263 | Model loading and weight management | â€¢ GGUF tensor parsing<br>â€¢ Q4_0, Q5_0, Q6_K dequantization<br>â€¢ KV cache initialization<br>â€¢ Tokenizer integration<br>â€¢ Sparsification parameters |
| `ZetaSampler.swift` | 150+ | Token sampling logic | â€¢ Accelerate-based vectorized sampling<br>â€¢ Entropy calculation (confusion metric)<br>â€¢ Energy/NLL calculation (variational)<br>â€¢ Top-K/Top-P filtering<br>â€¢ Banned token masking<br>â€¢ Superposition amplitude tracking |
| `ZetaTokenizer.swift` | ? | BPE tokenizer | â€¢ GGUF-compatible tokenization<br>â€¢ Encoding/decoding<br>â€¢ Special tokens handling |
| `QuantumLayers.swift` | ? | Quantum-inspired layer implementations | â€¢ Tunneling probability<br>â€¢ Resonance thresholds<br>â€¢ Sparsification config |
| `GGUFStubs.swift` | ? | GGUF format definitions | â€¢ Struct stubs for GGUF spec |
| `CompressionSupport.swift` | 255 | Model compression utilities | â€¢ Quantization helpers<br>â€¢ Sparsification analysis |
| `ModelFormatConverter.swift` | ? | Format conversion tools | â€¢ GGUF â†” MLX<br>â€¢ Quantization-aware handling |

---

## ğŸ¯ Metal Kernel Files (`Kernels/`)

### Metal Shader Kernels

| File | Purpose | Key Kernels |
|------|---------|-------------|
| `ZetaGGUFKernels.metal` | Core inference kernels | â€¢ `zeta_rms_norm_row` (RMS normalization)<br>â€¢ `zeta_q4_matmul` (quantized matmul)<br>â€¢ `zeta_float_matmul` (full precision matmul)<br>â€¢ `zeta_rope` (rotary positional embeddings)<br>â€¢ `zeta_score_calc` (attention scoring with Fine's theorem)<br>â€¢ `zeta_softmax` (attention softmax)<br>â€¢ `zeta_weighted_sum` (attention aggregation)<br>â€¢ `zeta_silu` (activation)<br>â€¢ `zeta_elem_mul` (element-wise multiply)<br>â€¢ `zeta_add` (element-wise add)<br>â€¢ `zeta_cache_update` (KV cache management)<br>â€¢ `zeta_gpu_sparsify` (GPU-accelerated sparsification)<br>â€¢ `zeta_q4_matmul_simd` (SIMD-optimized quantized matmul) |
| `ZetaOptimizedKernels.metal` | Advanced optimized kernels | â€¢ `zeta_fused_rmsnorm_matmul` (fused norm+matmul)<br>â€¢ `zeta_score_calc_simd` (SIMD attention scoring)<br>â€¢ Kernel fusion patterns |
| `ZetaUltraKernels.metal` | Extreme performance kernels | â€¢ `zeta_matmul_simdgroup_matrix` (AMX-accelerated matmul)<br>â€¢ `zeta_matmul_tiled` (tiled matmul)<br>â€¢ `zeta_flash_attention_v2` (Flash Attention)<br>â€¢ `zeta_fused_norm_rope_matmul` (3-way fusion)<br>â€¢ `zeta_swiglu_ultra` (fused gate/up/mul)<br>â€¢ `zeta_attention_async` (async operations) |

**Status:** Comprehensive kernel coverage with advanced optimizations

---

## ğŸš€ CLI & Executable Files (`CLI/`)

| File | Purpose | Arguments |
|------|---------|-----------|
| `main.swift` | Primary CLI interface | `--model <path>`, `--prompt <text>`, `--steps N`, `--variational <Îµ>`, `--ultimate`, `--allow-unk`, `--bench`, `--topk K`, `--topp P` |
| `ZetaBenchmarkCLI.swift` | GPU benchmarking tool | Model path, prompt, `--steps N`, `--zeta-on/off` |
| `ZetaSurgeryCLI.swift` | Sparsification tool | Input model, output path, sparsity config |

---

## ğŸ“‚ Loader Files (`Loaders/`)

### Universal Model Format Support

| File | Format | Status | Purpose |
|------|--------|--------|---------|
| `UniversalModelLoader.swift` | Protocol/Registry | âœ… Core | Base loader interface & factory pattern |
| `MLXUniversalLoader.swift` | MLX/Safetensors | âœ… Active | Apple MLX format support |
| `ONNXUniversalLoader.swift` | ONNX | âš ï¸ Partial | Basic ONNX loading |
| `PyTorchUniversalLoader.swift` | PyTorch | ğŸ”§ In Progress | PyTorch model support |
| `TensorFlowUniversalLoader.swift` | TensorFlow | ğŸ”§ Planned | TensorFlow format support |
| `SafetensorsUniversalLoader.swift` | Safetensors | ğŸ”§ Planned | Hugging Face safetensors format |
| `CoreMLUniversalLoader.swift` | CoreML | ğŸ”§ Planned | Apple CoreML format |
| `StreamingModelLoader.swift` | Streaming I/O | ğŸ”§ Planned | Memory-efficient streaming load |
| `ShardedModelLoader.swift` | Sharded models | ğŸ”§ Planned | Multi-file model support |
| `UNIVERSAL_LOADER_README.md` | Documentation | âœ… Reference | Loader architecture guide |

---

## ğŸ”Œ Format Parsers & Integrations

| File | Purpose | Status |
|------|---------|--------|
| `ONNXProtobufParser.swift` | ONNX protobuf parsing | âš ï¸ Partial |
| `ONNXRuntimeIntegration.swift` | ONNX Runtime bridge | ğŸ”§ Experimental |
| `GGUFStubs.swift` | GGUF format stubs | âœ… Active |

---

## ğŸ“Š Test & Benchmark Files (`Tests/`)

### Test Suite

| File | Type | Purpose |
|------|------|---------|
| `ZetaAttentionTests.swift` | Unit | Test attention mechanism correctness |
| `ZetaInferenceTests.swift` | Integration | End-to-end inference validation |
| `ZetaQ4KernelTests.swift` | Unit | Q4_0 quantization kernel tests |
| `ZetaTests.swift` | Unit | General component tests |
| `test_init.swift` | Integration | Engine initialization |
| `test_loader.swift` | Integration | Universal loader testing |
| `test_metal.swift` | Unit | Metal kernel validation |
| `test_model.swift` | Unit | Model loading & parsing |

### Benchmark Scripts

| File | Purpose | What It Tests |
|------|---------|---------------|
| `benchmark_throughput.sh` | Standard throughput | Tokens/sec with standard, optimized, and high-throughput modes |
| `benchmark_against_llamacpp.sh` | Comparative | Performance vs. llama.cpp baseline |
| `benchmark_fine_theory.sh` | Quantum metrics | Fine's Theorem quantum sparsification effectiveness |
| `quick_variational_test.sh` | Fast smoke test | Variational gating mode |
| `test_coherence_simple.sh` | Output quality | Generation coherence measurement |
| `test_variational_coherence.sh` | Variational quality | Coherence under energy-based gating |

---

## ğŸ§  Model Files (`models/`)

### PyTorch Models

```
models/pytorch/
â”œâ”€â”€ TinyLlama-1.1B-Chat-v1.0/
â”‚   â”œâ”€â”€ model.safetensors        (1.1B params, full precision)
â”‚   â”œâ”€â”€ config.json              (model architecture)
â”‚   â”œâ”€â”€ generation_config.json    (sampling params)
â”‚   â”œâ”€â”€ special_tokens_map.json   (special token defs)
â”‚   â”œâ”€â”€ tokenizer.json           (BPE vocabulary)
â”‚   â”œâ”€â”€ tokenizer_config.json     (tokenizer settings)
â”‚   â””â”€â”€ chat_template.jinja      (chat prompt template)
â”‚
â””â”€â”€ Zeta-Sparse-TinyLlama/
    â””â”€â”€ (Same structure, 28-42% sparsified version)
```

### ONNX Models

```
models/tinyllama-1.1b-chat-v1.0-onnx/
â”œâ”€â”€ onnx/
â”‚   â”œâ”€â”€ model.onnx                    (main model)
â”‚   â”œâ”€â”€ model.onnx_data               (tensor data)
â”‚   â”œâ”€â”€ decoder_model_merged.onnx     (decoder variant)
â”‚   â”œâ”€â”€ decoder_model_merged_quantized.onnx
â”‚   â”œâ”€â”€ model_fp16.onnx               (FP16 variant)
â”‚   â”œâ”€â”€ model_int8.onnx               (INT8 quantized)
â”‚   â”œâ”€â”€ model_q4.onnx                 (Q4 quantized)
â”‚   â”œâ”€â”€ model_bnb4.onnx               (bitsandbytes 4-bit)
â”‚   â””â”€â”€ ...                           (other quantization variants)
â”œâ”€â”€ config.json
â”œâ”€â”€ generation_config.json
â”œâ”€â”€ special_tokens_map.json
â”œâ”€â”€ tokenizer.json
â””â”€â”€ README.md
```

### GGUF Configurations

```
models/
â””â”€â”€ tinyllama-zeta.gguf.zeta-config    (Sparsification parameters)
    â”œâ”€â”€ zeta_s: 0.5
    â”œâ”€â”€ resonance_threshold: 0.3
    â”œâ”€â”€ tunneling_probability: 0.001
    â””â”€â”€ target_sparsity: 0.28
```

---

## ğŸ”§ Tools & Scripts (`Tools/`)

| File | Purpose |
|------|---------|
| `zeta_surgery.py` | Python script for Zeta-sparse pruning on PyTorch models |
| `ONNXUniversalLoader.swift` | Alternative ONNX loader implementation |

---

## ğŸ“„ Documentation Files

| File | Content | Audience |
|------|---------|----------|
| `README.md` | Main project overview | Everyone |
| `CONTRIBUTING.md` | Developer contribution guide | Contributors |
| `CODE_OF_CONDUCT.md` | Community standards | Community |
| `SECURITY.md` | Security policy & reporting | Security researchers |
| `CHANGELOG.md` | Version history | Maintainers, users |
| `FILE_INVENTORY.md` | This file | Developers, architects |
| `Loaders/UNIVERSAL_LOADER_README.md` | Loader architecture | Backend developers |

---

## ğŸ—ï¸ File Organization by Function

### **Inference Path (User Query â†’ Generation)**
```
CLI/main.swift
    â†“
ZetaGGUFEngine.swift (main orchestrator)
    â”œâ”€â†’ ZetaModel.swift (weights loading)
    â”œâ”€â†’ Kernels/*.metal (GPU compute)
    â”œâ”€â†’ ZetaSampler.swift (token selection)
    â””â”€â†’ ZetaTokenizer.swift (decode to text)
```

### **Model Loading Path (File â†’ Metal Buffers)**
```
Loaders/UniversalModelLoader.swift (factory)
    â”œâ”€â†’ MLXUniversalLoader.swift (if .mlx)
    â”œâ”€â†’ ONNXUniversalLoader.swift (if .onnx)
    â”œâ”€â†’ PyTorchUniversalLoader.swift (if .pt/.pth)
    â””â”€â†’ (Other format loaders)
        â†“
    ZetaModel.swift (GGUF parsing)
        â†“
    GPU: Metal buffers via ZetaGGUFEngine.swift
```

### **Testing Path**
```
Tests/*.swift (unit tests)
    â†“
Tests/*.sh (integration benchmarks)
    â†“
Results compared against llama.cpp baseline
```

---

## ğŸ“Š File Statistics Summary

| Category | Count | Notes |
|----------|-------|-------|
| **Core Engine Files** | 5 | GGUF engine, MPS engine, model, sampler, tokenizer |
| **Metal Kernels** | 3 | Core, optimized, ultra kernels |
| **Loaders** | 8 | GGUF, MLX, ONNX, PyTorch, TF, Safetensors, CoreML, Streaming/Sharded |
| **CLI/Tools** | 3 | Main CLI, benchmark, surgery |
| **Tests** | 11 | Unit tests + shell scripts |
| **Documentation** | 8 | README, guides, policies |
| **Model Files** | 20+ | PyTorch safetensors, ONNX variants, configs, tokenizers |

---

## ğŸ”‘ Key Implementation Locations

### Quantum Features

| Feature | Primary File | Kernel |
|---------|--------------|--------|
| **Zeta Resonant Recall** | `ZetaGGUFEngine.swift` (`encodeZetaAttention`) | `zeta_score_calc`, `zeta_softmax` |
| **Quantum Tunneling** | `ZetaGGUFKernels.metal` | `zeta_score_calc` (Bell zone logic) |
| **Fine's Theorem Sparsification** | `ZetaGGUFKernels.metal` | `zeta_gpu_sparsify` |
| **Quantum Superposition Sampling** | `ZetaSampler.swift` (`sampleSuperposition`) | CPU-based amplitude tracking |
| **Variational Gating** | `ZetaGGUFEngine.swift` (`variationalGate`) | Dual sparse/dense forward pass |
| **Entropy Calculation** | `ZetaSampler.swift` (`calculateEntropy`) | Accelerate framework |
| **Energy/NLL Calculation** | `ZetaSampler.swift` (`calculateNegativeLogLikelihood`) | Accelerate framework |

### Metal Optimizations

| Optimization | Files | Approach |
|--------------|-------|----------|
| **SIMD Vectorization** | `ZetaOptimizedKernels.metal`, `ZetaSampler.swift` | `float4`, `simd_sum`, NEON |
| **Kernel Fusion** | `ZetaOptimizedKernels.metal`, `ZetaUltraKernels.metal` | Combined ops (norm+matmul, gate+mul, etc.) |
| **Flash Attention** | `ZetaUltraKernels.metal` | Tiled attention with online softmax |
| **AMX Acceleration** | `ZetaUltraKernels.metal` | `simdgroup_matrix` for matmul |
| **Command Buffer Batching** | `ZetaGGUFEngine.swift` (`forwardPass`) | Single command buffer per token |
| **Buffer Pooling** | `ZetaGGUFEngine.swift` (`PreallocatedBuffers`) | Pre-allocated persistent buffers |

---

## âš ï¸ File Status & Maintenance Notes

### Active & Stable âœ…
- `ZetaGGUFEngine.swift` - Core inference engine
- `ZetaModel.swift` - Model loading
- `ZetaSampler.swift` - Sampling logic
- `ZetaGGUFKernels.metal` - Essential kernels
- All CLI tools
- All test files

### Experimental âš ï¸
- `ZetaMPSEngine.swift` - Alternative to main engine
- `ZetaOptimizedKernels.metal` - Advanced but not always used
- `ZetaUltraKernels.metal` - Extreme optimizations
- `ONNXRuntimeIntegration.swift` - Not fully tested

### In Progress ğŸ”§
- Several loaders in `Loaders/` directory
- `StreamingModelLoader.swift` - Not yet production-ready
- `ShardedModelLoader.swift` - Not yet production-ready
- `PyTorchUniversalLoader.swift` - Partial support

### Deprecated/Removed âŒ
- Old Metal kernel files (combined into Kernels/)
- Legacy optimizations

---

## ğŸ“ Notes for Development

1. **File Organization**: Code is split between root level (for now) and subdirectories (Engines/, Kernels/, Loaders/) for scalability
2. **Metal Compilation**: All `.metal` files are resources in `Package.swift` and compiled at runtime
3. **Loader Pattern**: Using Swift protocol + factory for extensible model format support
4. **Buffer Management**: Pre-allocated buffers reused across forward passes for zero hot-path allocation
5. **Testing**: Comprehensive test suite with both unit tests and shell-based benchmarks
6. **Documentation**: README and CONTRIBUTING guide users; inline comments document quantum features

---

**Generated:** December 9, 2025  
**Maintainer:** ZetaLm Team  
**License:** Apache License 2.0




















