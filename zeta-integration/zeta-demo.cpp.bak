// Z.E.T.A. Demo - Extended Context Inference with Metal Acceleration
//
// Demonstrates the full Z.E.T.A. pipeline:
// - Temporal decay (attention bias based on token age)
// - Sparse gating (threshold weak attention)
// - Memory management with prefetch
// - KV cache sublimation
// - Metal GPU acceleration for attention modification
//
// Z.E.T.A.(TM) | Patent Pending | (C) 2025 All rights reserved.

#include "arg.h"
#include "common.h"
#include "llama.h"
#include "sampling.h"
#include "ggml-backend.h"

#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <string>
#include <vector>
#include <chrono>
#include <algorithm>
#include <cmath>

// Z.E.T.A. memory headers (extern "C" linkage)
extern "C" {
#include "zeta-memory.h"
#include "zeta-integration.h"
#include "zeta-kv-extract.h"
#include "zeta-constitution.h"
}

// ============================================================================
// Z.E.T.A. Eval Callback for Attention Tracking
// ============================================================================

struct ZetaEvalContext {
    zeta_context_t* zeta;
    int current_pos;
    int n_kv;
    bool track_attention;
    std::vector<float> attention_weights;  // Accumulated attention weights
};

// Callback to track attention patterns during inference
static bool zeta_eval_callback(struct ggml_tensor* t, bool ask, void* user_data) {
    ZetaEvalContext* ctx = (ZetaEvalContext*)user_data;

    if (!ctx || !ctx->track_attention) return true;

    // We're looking for attention output tensors (KQV result)
    // The tensor name pattern varies by layer: "attn_out-0", "attn_out-1", etc.
    const char* name = ggml_get_name(t);
    if (!name) return true;

    // Check if this is an attention-related tensor
    if (strstr(name, "attn") != nullptr && strstr(name, "out") != nullptr) {
        if (!ask) {
            // After computation - we could analyze attention patterns here
            // For now, just note that attention was computed
        }
    }

    // Check for KQ (attention scores before softmax)
    if (strstr(name, "kq") != nullptr || strstr(name, "KQ") != nullptr) {
        if (!ask && t->type == GGML_TYPE_F32) {
            // This is the attention score matrix
            // We could extract and analyze attention patterns
            // For production, we'd accumulate these for sublimation decisions
        }
    }

    return true;  // Continue evaluation
}

static void print_usage(const char* prog) {
    fprintf(stderr, "\nUsage: %s -m model.gguf [options]\n", prog);
    fprintf(stderr, "\nZ.E.T.A. Extended Context Options:\n");
    fprintf(stderr, "  --zeta-lambda N       Temporal decay rate (default: 0.01, 0 = disabled)\n");
    fprintf(stderr, "  --zeta-tau N          Sparse gating threshold (default: 0.01, large negative = disabled)\n");
    fprintf(stderr, "  --zeta-retrieve N     Retrieval similarity threshold (default: 0.3)\n");
    fprintf(stderr, "  --zeta-momentum N     Query momentum coefficient (default: 0.3)\n");
    fprintf(stderr, "  --zeta-storage DIR    Storage directory for archived blocks (default: /tmp/zeta)\n");
    fprintf(stderr, "  --zeta-constitution F Path to constitution file (required for model binding)\n");
    fprintf(stderr, "  --zeta-track-attention Enable eval callback attention tracking (debug; slows decode)\n");
    fprintf(stderr, "  --zeta-no-load-existing Do not load existing .zeta blocks from storage dir\n");
    fprintf(stderr, "\nPerformance note:\n");
    fprintf(stderr, "  This demo derives the Z.E.T.A. query vector from top-k logits to avoid per-token embedding readback (which can be very slow with Metal).\n");
    fprintf(stderr, "\nExample:\n");
    fprintf(stderr, "  %s -m model.gguf -p \"Once upon a time\" -n 100 --zeta-constitution CONSTITUTION.txt\n\n", prog);
}

static inline uint64_t zeta_splitmix64(uint64_t & x) {
    x += 0x9e3779b97f4a7c15ULL;
    uint64_t z = x;
    z = (z ^ (z >> 30)) * 0xbf58476d1ce4e5b9ULL;
    z = (z ^ (z >> 27)) * 0x94d049bb133111ebULL;
    return z ^ (z >> 31);
}

static void zeta_query_from_logits_topk(
    const float * logits,
    int n_vocab,
    int n_embd,
    int top_k,
    std::vector<float> & out
) {
    out.assign(n_embd, 0.0f);

    if (!logits || n_vocab <= 0 || n_embd <= 0) {
        return;
    }

    top_k = std::max(1, std::min(top_k, n_vocab));

    std::vector<int> best_idx(top_k, -1);
    std::vector<float> best_val(top_k, -INFINITY);

    for (int i = 0; i < n_vocab; i++) {
        const float v = logits[i];

        int worst = 0;
        for (int k = 1; k < top_k; k++) {
            if (best_val[k] < best_val[worst]) {
                worst = k;
            }
        }

        if (v > best_val[worst]) {
            best_val[worst] = v;
            best_idx[worst] = i;
        }
    }

    const float max_logit = *std::max_element(best_val.begin(), best_val.end());
    std::vector<float> w(top_k, 0.0f);
    float wsum = 0.0f;
    for (int k = 0; k < top_k; k++) {
        if (best_idx[k] < 0) continue;
        const float wk = std::exp(best_val[k] - max_logit);
        w[k] = wk;
        wsum += wk;
    }
    if (wsum <= 0.0f) {
        return;
    }
    for (int k = 0; k < top_k; k++) {
        w[k] /= wsum;
    }

    // Hash token ids into an n_embd vector using deterministic pseudo-random features.
    for (int k = 0; k < top_k; k++) {
        const int tid = best_idx[k];
        if (tid < 0) continue;

        const float wk = w[k];
        uint64_t seed = 0x6a09e667f3bcc909ULL ^ (uint64_t) tid * 0x9e3779b97f4a7c15ULL;

        for (int d = 0; d < n_embd; d++) {
            const uint64_t r = zeta_splitmix64(seed);
            const float rf = (float) ((int32_t) (r & 0xffffffffu)) / 2147483648.0f; // [-1, 1)
            out[d] += wk * rf;
        }
    }

    // L2 normalize.
    double ss = 0.0;
    for (int d = 0; d < n_embd; d++) {
        ss += (double) out[d] * (double) out[d];
    }
    if (ss > 0.0) {
        const float inv = 1.0f / std::sqrt((float) ss);
        for (int d = 0; d < n_embd; d++) {
            out[d] *= inv;
        }
    }
}

int main(int argc, char** argv) {
    common_params params;

    // Z.E.T.A. specific parameters
    float zeta_lambda = 0.01f;
    float zeta_tau = 0.01f;
    float zeta_retrieve = 0.1f;  // Lower threshold for logits-derived queries
    float zeta_momentum = 0.3f;
    std::string zeta_storage = "/tmp/zeta";
    std::string zeta_constitution = "";  // Path to constitution file (empty = use embedded)
    bool zeta_track_attention = false;
    bool zeta_no_load_existing = false;

    // Pre-parse Z.E.T.A. specific args and filter them from argv
    std::vector<char*> filtered_argv;
    filtered_argv.push_back(argv[0]);

    for (int i = 1; i < argc; i++) {
        if (strcmp(argv[i], "--zeta-constitution") == 0 && i + 1 < argc) {
            zeta_constitution = argv[++i];
        } else if (strcmp(argv[i], "--zeta-storage") == 0 && i + 1 < argc) {
            zeta_storage = argv[++i];
        } else if (strcmp(argv[i], "--zeta-retrieve") == 0 && i + 1 < argc) {
            zeta_retrieve = std::stof(argv[++i]);
        } else if (strcmp(argv[i], "--zeta-momentum") == 0 && i + 1 < argc) {
            zeta_momentum = std::stof(argv[++i]);
        } else if (strcmp(argv[i], "--zeta-track-attention") == 0) {
            zeta_track_attention = true;
        } else if (strcmp(argv[i], "--zeta-no-load-existing") == 0) {
            zeta_no_load_existing = true;
        } else {
            filtered_argv.push_back(argv[i]);
        }
    }

    int filtered_argc = (int)filtered_argv.size();

    // Parse standard params (without Z.E.T.A. args)
    if (!common_params_parse(filtered_argc, filtered_argv.data(), params, LLAMA_EXAMPLE_COMPLETION, nullptr)) {
        print_usage(argv[0]);
        return 1;
    }

    // Override with Z.E.T.A. params from common_params
    if (params.zeta_temporal_lambda != 0.0f) {
        zeta_lambda = params.zeta_temporal_lambda;
    }
    if (params.zeta_tunneling_threshold > -1e9f) {
        zeta_tau = params.zeta_tunneling_threshold;
    }

    // Set env vars for Metal kernel
    setenv("ZETA_TEMPORAL_LAMBDA", std::to_string(zeta_lambda).c_str(), 1);
    setenv("ZETA_TUNNELING_THRESHOLD", std::to_string(zeta_tau).c_str(), 1);
    if (zeta_no_load_existing) {
        setenv("ZETA_NO_LOAD_EXISTING", "1", 1);
    }

    fprintf(stderr, "\n=== Z.E.T.A. Demo ===\n");
    fprintf(stderr, "Temporal decay (λ):    %.4f\n", zeta_lambda);
    fprintf(stderr, "Sparse gating (τ):     %.4f\n", zeta_tau);
    fprintf(stderr, "Retrieve threshold:    %.2f\n", zeta_retrieve);
    fprintf(stderr, "Query momentum (γ):    %.2f\n", zeta_momentum);
    fprintf(stderr, "Storage directory:     %s\n", zeta_storage.c_str());
    fprintf(stderr, "Constitution:          %s\n", zeta_constitution.empty() ? "(embedded)" : zeta_constitution.c_str());
    fprintf(stderr, "=====================\n\n");

    common_init();
    llama_backend_init();
    llama_numa_init(params.numa);

    // Load model
    auto mparams = common_model_params_to_llama(params);
    llama_model* model = llama_model_load_from_file(params.model.path.c_str(), mparams);
    if (!model) {
        fprintf(stderr, "Failed to load model: %s\n", params.model.path.c_str());
        return 1;
    }

    // Create context - DISABLE embeddings for performance!
    // Embeddings add ~115ms/token overhead (20x slowdown)
    // Instead, we use logits as query proxy for memory retrieval
    params.embedding = false;
    auto cparams = common_context_params_to_llama(params);
    cparams.embeddings = false;  // CRITICAL: Keep disabled for ~190 tok/s

    // Eval callback - off by default (can be expensive depending on backend)
    ZetaEvalContext eval_ctx = {};
    eval_ctx.track_attention = zeta_track_attention;
    if (zeta_track_attention) {
        cparams.cb_eval = zeta_eval_callback;
    }
    cparams.cb_eval_user_data = &eval_ctx;

    llama_context* ctx = llama_init_from_model(model, cparams);
    if (!ctx) {
        fprintf(stderr, "Failed to create context\n");
        llama_model_free(model);
        return 1;
    }

    // Initialize Z.E.T.A. memory manager with constitutional lock
    zeta_context_t* zeta = zeta_context_init(
        ctx,
        zeta_storage.c_str(),
        zeta_constitution.empty() ? nullptr : zeta_constitution.c_str(),
        zeta_lambda,
        zeta_tau,
        zeta_retrieve,
        zeta_momentum
    );

    if (!zeta) {
        fprintf(stderr, "Failed to initialize Z.E.T.A. context\n");
        llama_free(ctx);
        llama_model_free(model);
        return 1;
    }

    // Link eval context to Z.E.T.A. context
    eval_ctx.zeta = zeta;
    eval_ctx.n_kv = llama_n_ctx(ctx);
    eval_ctx.attention_weights.resize(eval_ctx.n_kv, 0.0f);

    // Report Metal status
    if (zeta_metal_is_available(zeta)) {
        fprintf(stderr, "[Z.E.T.A.] Metal GPU acceleration ACTIVE\n");
    } else {
        fprintf(stderr, "[Z.E.T.A.] Using CPU fallback (Metal unavailable)\n");
    }

    // Get vocab
    const llama_vocab* vocab = llama_model_get_vocab(model);
    int n_embd = llama_model_n_embd(model);

    // Tokenize prompt
    std::vector<llama_token> tokens = common_tokenize(vocab, params.prompt, true);
    int n_prompt = tokens.size();
    int n_ctx = llama_n_ctx(ctx);

    fprintf(stderr, "Prompt tokens: %d, Context size: %d\n", n_prompt, n_ctx);

    if (n_prompt > n_ctx) {
        fprintf(stderr, "Prompt too long for context size\n");
        zeta_context_free(zeta);
        llama_free(ctx);
        llama_model_free(model);
        return 1;
    }

    // Create sampler
    common_sampler* smpl = common_sampler_init(model, params.sampling);
    if (!smpl) {
        fprintf(stderr, "Failed to create sampler\n");
        zeta_context_free(zeta);
        llama_free(ctx);
        llama_model_free(model);
        return 1;
    }

    // Create batch
    llama_batch batch = llama_batch_init(n_prompt, 0, 1);

    // Add prompt tokens to batch
    for (int i = 0; i < n_prompt; i++) {
        common_batch_add(batch, tokens[i], i, {0}, false);
    }
    batch.logits[batch.n_tokens - 1] = true;

    // Query vector buffer for Z.E.T.A.
    int n_vocab = llama_vocab_n_tokens(vocab);
    std::vector<float> query_vec(n_embd);

    // Process prompt
    fprintf(stderr, "Processing prompt...\n");

    if (llama_decode(ctx, batch) != 0) {
        fprintf(stderr, "llama_decode() failed for prompt\n");
        common_sampler_free(smpl);
        llama_batch_free(batch);
        zeta_context_free(zeta);
        llama_free(ctx);
        llama_model_free(model);
        return 1;
    }

    // Use logits as query proxy (embeddings disabled for performance)
    const float* prompt_logits = llama_get_logits(ctx);
    zeta_query_from_logits_topk(prompt_logits, n_vocab, n_embd, /*top_k=*/16, query_vec);

    // Z.E.T.A. pre-decode with valid query (for retrieval from existing memory)
    zeta_pre_decode(zeta, query_vec.data(), n_embd);

    // Archive prompt KV cache as a memory block for superposition demo
    // Use logits-derived query_vec as summary to match query representation space
    if (n_prompt > 4) {
        // Extract KV cache with logits-derived summary (ensures retrieval works)
        int64_t block_id = zeta_sublimate_kv_cache_with_summary(
            zeta,
            ctx,
            0,              // seq_id
            -1,             // layer_idx: -1 = mean of all layers
            0,              // pos_start
            n_prompt,       // pos_end
            query_vec.data(),  // Use logits-derived query as summary
            n_embd
        );

        if (block_id >= 0) {
            fprintf(stderr, "Archived prompt KV cache as memory block %lld (logits-derived summary)\n", (long long)block_id);
        } else {
            // Fallback to logits-derived vector if KV extraction fails
            if (prompt_logits) {
                block_id = zeta_archive_hidden_states(zeta, query_vec.data(), 1, 0);
                if (block_id >= 0) {
                    fprintf(stderr, "Archived prompt logits (fallback) as memory block %lld\n", (long long)block_id);
                }
            }
        }
    }

    // Print prompt
    fprintf(stderr, "\n--- Output ---\n");
    printf("%s", params.prompt.c_str());
    fflush(stdout);

    // Generation loop with Metal-accelerated retrieval
    int n_cur = n_prompt;
    int n_gen = params.n_predict > 0 ? params.n_predict : 100;

    // Performance timing
    auto gen_start = std::chrono::high_resolution_clock::now();
    int64_t total_retrieval_us = 0;
    int64_t total_decode_us = 0;
    int retrieval_count = 0;

    // Note: We intentionally avoid doing an extra full similarity pass here.
    // `zeta_pre_decode()` already scans blocks to decide what to prefetch/inject.

    for (int i = 0; i < n_gen; i++) {
        // Sample next token
        llama_token new_token = common_sampler_sample(smpl, ctx, -1);
        common_sampler_accept(smpl, new_token, true);

        // Check for EOS
        if (llama_vocab_is_eog(vocab, new_token)) {
            fprintf(stderr, "\n[EOS]\n");
            break;
        }

        // Print token
        std::string token_str = common_token_to_piece(ctx, new_token);
        printf("%s", token_str.c_str());
        fflush(stdout);

        // Prepare next batch
        common_batch_clear(batch);
        common_batch_add(batch, new_token, n_cur, {0}, true);

        // Update eval context position
        eval_ctx.current_pos = n_cur;

        // Check if we need to sublimate (archive old KV cache blocks)
        // Use attention-based policy if available
        int sublimated = zeta_auto_sublimate(zeta, n_cur, llama_n_ctx(ctx));
        if (sublimated > 0) {
            fprintf(stderr, "\n[Z.E.T.A. auto-sublimated %d tokens at pos %d]\n", sublimated, n_cur);
        }

        // Decode with timing
        auto decode_start = std::chrono::high_resolution_clock::now();
        if (llama_decode(ctx, batch) != 0) {
            fprintf(stderr, "\nllama_decode() failed at token %d\n", n_cur);
            break;
        }
        auto decode_end = std::chrono::high_resolution_clock::now();
        total_decode_us += std::chrono::duration_cast<std::chrono::microseconds>(decode_end - decode_start).count();

        // Use logits as query proxy (embeddings disabled for performance)
        const float* cur_logits = llama_get_logits(ctx);
        bool has_valid_query = cur_logits != nullptr;
        if (has_valid_query) {
            zeta_query_from_logits_topk(cur_logits, n_vocab, n_embd, /*top_k=*/16, query_vec);
        }

        // Checkpoint sublimation every 512 tokens (AFTER query_vec update so summary matches)
        if (n_cur > 0 && n_cur % 512 == 0 && has_valid_query) {
            fprintf(stderr, "\n[Z.E.T.A. checkpoint at token %d]\n", n_cur);

            int32_t pos_start = n_cur - 512;
            int32_t pos_end = n_cur;

            int64_t block_id = zeta_sublimate_kv_cache_with_summary(
                zeta,
                ctx,
                0,              // seq_id
                -1,             // layer_idx: -1 = mean of all layers
                pos_start,
                pos_end,
                query_vec.data(),  // Fresh query from current logits
                n_embd
            );

            if (block_id >= 0) {
                fprintf(stderr, "[Sublimated KV cache (pos %d-%d) as block %lld]\n",
                        pos_start, pos_end, (long long)block_id);
            }
        }

        // Z.E.T.A. pre-decode (prefetch, momentum update, retrieval scan)
        auto retrieval_start = std::chrono::high_resolution_clock::now();
        if (has_valid_query) {
            zeta_pre_decode(zeta, query_vec.data(), n_embd);
            if (zeta->memory->num_blocks > 0) {
                retrieval_count++;
            }
        }
        auto retrieval_end = std::chrono::high_resolution_clock::now();
        total_retrieval_us += std::chrono::duration_cast<std::chrono::microseconds>(retrieval_end - retrieval_start).count();

        // Z.E.T.A. superposition injection
        // Inject attention from archived memory blocks into hidden state
        float retrieval_score = 0.0f;
        if (zeta->memory->num_blocks > 0 && has_valid_query) {
            // Create a modifiable copy for injection (use query_vec as proxy)
            std::vector<float> hidden_state(query_vec.begin(), query_vec.end());

            // Inject superposition: O = O_ctx + Σ(α_k · O_mem_k)
            zeta_inject_superposition(zeta, query_vec.data(), hidden_state.data(), n_embd);

            // Get retrieval score for adaptive sampling
            zeta_stats_t stats;
            zeta_get_statistics(zeta, &stats);
            retrieval_score = stats.avg_retrieval_score;

            // Apply logit bias based on memory injection
            // When retrieval score is high, boost confidence in top tokens
            if (retrieval_score > 0.5f) {
                float* logits = llama_get_logits_ith(ctx, 0);
                if (logits) {
                    // Scale logits by (1 + alpha * retrieval_score)
                    // This increases confidence when memory is relevant
                    float alpha = 0.3f * retrieval_score;
                    for (int v = 0; v < n_vocab; v++) {
                        // Amplify differences from mean (increases confidence)
                        logits[v] *= (1.0f + alpha);
                    }
                }
            }
        }

        n_cur++;
    }

    auto gen_end = std::chrono::high_resolution_clock::now();
    int64_t total_gen_us = std::chrono::duration_cast<std::chrono::microseconds>(gen_end - gen_start).count();

    printf("\n");
    fprintf(stderr, "\n--- Generation complete ---\n");
    int tokens_generated = n_cur - n_prompt;
    fprintf(stderr, "Total tokens generated: %d\n", tokens_generated);

    // Performance report
    fprintf(stderr, "\n=== Z.E.T.A. Performance ===\n");
    fprintf(stderr, "Total generation time:   %.2f ms\n", total_gen_us / 1000.0);
    fprintf(stderr, "Total decode time:       %.2f ms (%.1f%%)\n",
            total_decode_us / 1000.0, 100.0 * total_decode_us / total_gen_us);
    fprintf(stderr, "Total retrieval time:    %.2f ms (%.1f%%)\n",
            total_retrieval_us / 1000.0, 100.0 * total_retrieval_us / total_gen_us);
    if (tokens_generated > 0) {
        fprintf(stderr, "Tokens/second:           %.2f\n",
                tokens_generated * 1000000.0 / total_gen_us);
        fprintf(stderr, "Avg decode latency:      %.2f ms/token\n",
                total_decode_us / 1000.0 / tokens_generated);
        fprintf(stderr, "Avg retrieval latency:   %.3f ms/token\n",
                total_retrieval_us / 1000.0 / tokens_generated);
    }
    fprintf(stderr, "GPU retrievals:          %d\n", retrieval_count);
    fprintf(stderr, "Metal acceleration:      %s\n",
            zeta_metal_is_available(zeta) ? "ACTIVE" : "inactive (CPU)");
    fprintf(stderr, "============================\n");

    // Print final Z.E.T.A. statistics
    zeta_print_statistics(zeta);

    // Cleanup
    common_sampler_free(smpl);
    llama_batch_free(batch);
    zeta_context_free(zeta);
    llama_free(ctx);
    llama_model_free(model);
    llama_backend_free();

    return 0;
}
